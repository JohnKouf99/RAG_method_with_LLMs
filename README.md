This repo is trying to implement the RAG method in LLMs. Ollama's llama3.1:8b model is utilized for this purrpose. The RAG data were harvested online and are used in conjuction with the LLMs internal knowledge. The claims and the external resources are in Greek language. 
This project is implemented in order to assess the LLM's capabilities in filtering news and in the production of justification.
